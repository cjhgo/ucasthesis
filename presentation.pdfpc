[file]
presentation.pdf
[notes]
### 1
各位老师同学下午好
我今天答辩的题目是 xxx
### 2
我将从以下这4个方面来进行今天的报告
### 3
首先我来介绍一下本论文的研究背景-图计算
图计算指的是针对大规模图数据进行的分布式计算
如图中所示，很多领域的很多问题产生了大规模的图结构的数据
为此人们开发了很多专用的分布式图计算框架
### 4
在分布式图计算中有一个副本点的概念
它指定是图被分布式划分之后，顶点同时存在于多台机器上有多个副本
副本点相应地引起一个问题，系统如何维护它们之间的数据一致
### 5
传统的图计算系统多采用急切数据一致性的方法
这种方法把多个副本点看作不可分割的原子整体，
在标记为master的副本点上进行读写，在标记为mirror的副本点上只读
然后通过拷贝保证多个副本点之间的数据一致
这种方法虽然解决了数据一致的问题，但是存在着集群之间频繁的通信和同步等待
针对这一问题，我们提出了一种 延迟数据一致性方法
它把多个副本看作互相独立的点，可以各自更新，通过计算实现数据一致

这里给出了 这两种方法的一个对比

### 6

延迟数据一致性方法保留了副本点的好处
克服了急切数据一致性方法的缺点
极大地提升了图计算的效率
这里给出了它的一个性能评测的结果

以上就是论文研究背景的一个介绍
即分布式图计算系统中的延迟数据一致性方法，这种方法简称为 LazyAsync

### 7 
接下来我来介绍论文的研究动机- LazyAsync 的开启策略问题
LazyAsync 的开启策略 指的是系统何时启用延迟数据一致性
图中给出了 LazyAsync 的一次迭代过程，它包含本地计算 和 数据一致性阶段
没有开启延迟数据一致性时，迭代过程中不存在本地计算，计算是普通的基于数据交换的计算
开启之后迭代过程中就有了本地计算的过程
图计算由多轮迭代计算构成，最终收敛
那么我们选择开启策略时就有多种选择
既可以立即开启，也可以指定 第1轮，第2轮或其他轮次之后来开启

在实验过程中，我们发现
不同的开启策略会得到不同的性能提升效果

针对这一现象，我们就有两个问题

第一，为什么不同的开启策略会得到不同的性能提升效果
第二，什么样的开启策略能得到相对最优的性能提升效果

### 8 
在之前的工作中
我们其实也找到了一种基于决策树的开启策略
它是通过手动调优然后数据拟合来实现的
本质上是一种离线方法，并且存在着失灵的情况
我们对这种方法并不满意

### 9
以上就是对论文的研究动机的一个介绍
即 面向 LazyAsync 的自适应优化方法研究
论文希望解决三个问题

1. 开启策略如何影响性能提升效果
2. 如何找到一种开启策略使之得到相对最优的性能提升效果
3. 这种开启策略应该克服 之前决策树方法的 缺点和缺陷

### 10
最终针对这些问题，论文得到了三个研究结果

第一个结果是
冗余计算是不同开启策略造成 LazyAsync 性能波动的根源
第一个研究结果
图计算过程存在着解的局部性规律可以减少冗余计算
第三个研究结果是
基于解的局部性规律实现了一种自适应优化方法
解决了开启策略的问题

接下来我对三个研究结果分别进行介绍

### 11

首先是对第一个研究结果的介绍

这里有一个小图
通过对比，具体展示了 LazyAsync 的性能收益的来源
即它的本地计算阶段能对子图中的顶点提前激活计算使之收敛
从而减少了系统整体的迭代轮次，也减少了系统中的消息交换

### 12
但是在这里又有一个小图给出了一种现象
本地计算带来的性能收益并不是必然地
本地计算的子图中提前激活的顶点上也有可能是冗余无效的
那么此时本地计算带来的就不是性能收益，而是性能损耗
也就是说
LazyAsync 拿到性能收益的地方也有可能是它造成性能损失的地方

仔细思考 LazyAsync 的原理
我们也能知道这一现象时很自然地

本地计算到后边肯定是不准确的，存在着冗余计算

### 13

但是如何研究冗余计算 对 LazyAsync 性能提升的具体影响呢
我们首先需要一种定量的方式来观察冗余计算

冗余计算说的就是计算得到的结果是无效地，因而不产生性能收益
那么 比较 计算结果和目标结果，我们就知道计算是有效还是无效的了
但是目标结果是算了之后才知道的
对此论文中采取 先算一遍，把最终解存到顶点上，然后比较迭代解和最终解的方式来度量冗余计算

随后 本研究以 sssp 算法为例，在4个 需要手动调优的输入图上进行了实验

### 14
实验结果如图所示

### 15
分析实验结果，我们有以下几点发现
1 手动调优找到的最后策略中几乎不存在冗余计算
2 性能最差的立即进入策略中 整体存在 20%-80 的冗余计算
3 在某次迭代中 本地计算激活了 156万个顶点，但只有 6万个顶点 是有效地
冗余计算的比例达到了 96%

好的开启策略不存在冗余计算性能最好
差的开启策略存在 20-80 的冗余计算 性能最差
我们可以认为

正是冗余计算造成了 不同开启策略下 LazyAsync 的性能波动

### 16 
找到了性能波动产生的原因之后
我们自然地想到如何 减少 冗余计算

为此我们要先介绍以下 图计算中 的全局解 和局部性的概念

图计算中顶点有多个副本点
在 LazyAsync 中， 顶点的全局解也就由多个激活的副本上的局部解构成

在图计算过程中 
顶点的全局解 有可能完全由 某个局部解 决定
也有可能由多个局部解决定

### 17

当全局解只由某个局部解决定时
由于这个局部解就等于全局解
所以它的本地计算中不会直接引起冗余计算
当情况相反时
由于每个局部解都不等于全局解
所以它的本地计算会直接引起冗余计算

这里给出一个小图来形象化地展示这一点

### 18 

针对 这样的现象
我们提出一种假设
如果一次迭代过程中
大多数活跃点的全局解都只由单个局部解构成
那么此时 开启延迟数据一致
则不会直接带来冗余计算
因而是一个好的开启时机

这一假设，我们称之为 解的局部性
这里给出了一个具体的例子
可以看到
一些顶点虽然有多个副本点
但是 其全局解只由单个局部解决定


### 19
为了观察这个现象
我们还是需要找到一种定量度量 全局解和局部解的方法

在图计算中
局部解被包含在消息中然后发送给标记为 master 的副本点
所以 master 副本点能够看到所有局部解，同时也负责产生全局解

所以通过在顶点上添加数据结构，我们能够记录每次迭代时的全局解和局部解
然后通过分析 这些记录的数据
我们就实现了 对 全局解好局部解的定量度量

随后我们在 3种算法和8个输入图的 24个组合上进行了实验
得到如下的结果

### 23

分析这些实验结果 我们可以看到
1. 在每种组合上， 解的局部性规律都是存在的
2. 在局部性较好的图上， 解的局部性一直存在
3. 在局部性不好的图上， 解的局部性在迭代进行一段时间后才存在

### 24

总结这些分析，我们可以得结论

图计算过程中普遍存在着解的局部性规律
并且这种规律的出现是动态的

### 25
以上就是本研究的第2个研究结果
梳理一下就是
在第一个研究结果中我们发现了冗余计算造成了 不同开启策略下 LazyAsync 性能波动
在第二个研究结果中我们发现 图计算过程中存在着解的局部性规律，它有力减少冗余计算

那么很自然地，我们希望
基于解的局部性规律来选择开启策略，从而减少冗余计算，得到相对最好的性能提升


但是前边我们研究解的局部性规律时采用地依旧是一种离线事后分析的方法
我们需要在线地动态统计 解的局部性规律

分析前边对解的局部性规律的研究我们发现
解的局部性只和全局解和局部解之间的数量关系有关
在线统计时，我们不需要关系 它们之间的数值关系
因此我们不需要存储每次迭代时它们的值，只需要判断 局部解的个数就可以指定某个顶点是否具有解的局部性

基于这一思路，我们成功实现了对 全局解和局部解关系地在线统计

基于在线统计，我们最终实现了 基于解的局部性的自适应优化方法
它的伪代码如下，有两个部分构成

### 26
第一个部分就是 如何在线统计
### 27
第二个部分就是基于在线统计自适应地选择开启策略

### 28

最后，基于这个方法
我们在 4种算法和8个输入图进行了实验
得到了如下的性能评测结果

### 29

可以看到

基于解的局部性的自适应优化方法
自动地得到了 和手动调优相一致的性能提升效果


### 30 

然后是对本论文研究内容的总结

论文对 LazyAsync 的自适应优化问题进行研究
得到了以下这三个研究结果

### 31

通过这三个研究结果
我们之前提出的
LazyAsync 真正成为了一个完善实用的方法

### 32

最后
谢谢各位老师的耐心聆听
请各位老师批评指正